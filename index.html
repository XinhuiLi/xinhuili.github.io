<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Xinhui  Li


</title>
<meta name="description" content="Personal Website">

<!-- Open Graph -->

<meta property="og:site_name" content="Personal Website" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="/" />
<meta property="og:description" content="about" />
<meta property="og:image" content="" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒ±</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/bookshelf/">
                bookshelf
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/assets/cv/cv_xli_09_25.pdf">
                cv
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Xinhui</span>  Li
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/Xinhui23.jpg">
      
      
    </div>
    

    <div class="clearfix">
      <p>My name is Xinhui Li (é»Žæ¬£æƒ ). I am a final-year Ph.D. candidate in Electrical and Computer Engineering at <a href="https://coe.gatech.edu/">Georgia Institute of Technology</a> and <a href="https://trendscenter.org/">Center for Translational Research in Neuroimaging and Data Science (TReNDS)</a>, advised by <a href="https://scholar.google.com/citations?user=WNOoGKIAAAAJ&amp;hl=en">Prof. Vince D. Calhoun</a> and <a href="https://scholar.google.com/citations?user=cMtwwG8AAAAJ&amp;hl=en">Dr. Rogers F. Silva</a>. During my PhD, I interned at <a href="https://www.amazon.science/">Amazon Science</a> working on video understanding with vision-language models. Previously, I developed a software pipeline <a href="https://fcp-indi.github.io/">C-PAC</a> for MRI preprocessing and investigated <a href="https://www.nature.com/articles/s41562-024-01942-4">interpipeline agreement</a> at <a href="https://childmind.org/">Child Mind Institute</a>.</p>

<p>I used to be an engineer dreaming of connecting the brain and the computer, and now I am growing as a scientist attempting to solve fundamental problems in neuroscience and computer science. My current research interests include representation learning, multimodal neuroimaging analysis, and AI for health and science. To gain a comprehensive understanding of the brain, I am developing a deep multidataset subspace analysis framework that includes linear and nonlinear latent variable models (ICA/IVA/ISA) to learn linked and identifiable representations from multimodal neuroimaging datasets. Lately, I have become interested in language model interpretability and safety. I believe safe AI is a prerequisite of beneficial AI. More generally, I am fascinated by both biological and artificial intelligence. I think understanding the principles of neural computation will likely help us develop more flexible algorithms and build more energy-efficient machines. Please feel free to reach out if you want to discuss research questions or collaboration opportunities.</p>

<p>I love art in many forms. I often spend my free time at museums and theaters. I also collaborate with talented artists to create artwork related to my research, such as <a href="https://sciartwonderatl.wixsite.com/sawatl/copy-of-kaufman-hatzell">Butterfly Effect</a> and <a href="https://www.youtube.com/watch?v=yph2hXzY9Dc">Schizosymphony</a>. I am happily married to <a href="https://yannan-chen.github.io/">Yannan Chen</a>.</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Oct 28, 2025</th>
          <td>
            
              Our paper, AI Psychiatrist Assistant: An LLM-based Multi-Agent System for Depression Assessment from Clinical Interviews, is accepted at <a href="https://ahli.cc/ml4h">the Machine Learning for Health Symposium (ML4H)</a> proceedings track. Super proud of our brilliant students!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 28, 2025</th>
          <td>
            
              Our paper, <a href="https://arxiv.org/abs/2508.17675">Towards Synthesizing Normative Data for Cognitive Assessments Using Generative Multimodal Large Language Models</a>, is accepted at <a href="https://genai4health.github.io/">the GenAI4Health workshop</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 11, 2025</th>
          <td>
            
              I am accepted to the Technical AI Safety Fellowship Program at <a href="https://www.aisi.dev/">Georgia Tech AI Safety Initiative (AISI)</a>. I look forward to learning and contributing to AI safety research.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 26, 2025</th>
          <td>
            
              I give a talk on <a href="https://drive.google.com/file/d/1qSHPoN7m03CUPQRr1a8yUS5NyyxDAWWV/view?usp=sharing">Deep Generative Modeling for Latent Source Separation and Psychosis Continuum Estimation from Neuroimaging Data</a> at the <a href="https://www.humanbrainmapping.org/i4a/pages/index.cfm?pageid=4229">OHBM</a> Symposium Machine Learning for Brain Imaging: Predicting Traits, Disease Progression, and Treatment Response.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec 10, 2024</th>
          <td>
            
              We won the first place at the <a href="https://mexa.app/">Mental Health X AI (MEXA) Hackathon</a>! We proposed using large language models to assist with clinical interview transcript generation and analysis.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 19, 2024</th>
          <td>
            
              Our paper, <a href="https://doi.org/10.1002/hbm.70037">A Method for Multimodal IVA Fusion Within a MISA Unified Model Reveals Markers of Age, Sex, Cognition, and Schizophrenia in Large Neuroimaging Studies</a>, is published in Human Brain Mapping!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug 5, 2024</th>
          <td>
            
              My first first-author journal paper, <a href="https://www.nature.com/articles/s41562-024-01942-4">Moving beyond processing- and analysis-related variation in resting-state functional brain imaging</a>, is published in Nature Human Behaviour!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 13, 2024</th>
          <td>
            
              I am excited to start my first industrial internship as a data scientist at Amazon this summer!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 29, 2024</th>
          <td>
            
              Our paper, <a href="https://icad2024.icad.org/wp-content/uploads/2024/06/ICAD_2024_paper_69.pdf">Schizosymphony: From Schizophrenia Brainwaves To Narrative Soundscapes</a>, is accepted as an oral presentation at <a href="https://icad2024.icad.org/">ICAD 2024</a>! This is my first time collaborating with a composer. We try to create an urban soundscape using fMRI data of a schizophrenia patient.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 15, 2024</th>
          <td>
            
              Our paper, <a href="https://ieeexplore.ieee.org/document/10781829">DeepSeg: A transfer-learning segmentation tool for limited sample training of nonhuman primate MRI</a>, is accepted at <a href="https://embc.embs.org/2024/">EMBC 2024</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 1, 2024</th>
          <td>
            
              Our paper, <a href="https://www.sciencedirect.com/science/article/pii/S0006322323015925">A Brainwide Risk Score for Psychiatric Disorder Evaluated in a Large Adolescent Population Reveals Increased Divergence Among Higher-Risk Groups Relative to Control Participants</a>, is published in Biological Psychiatry!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 19, 2024</th>
          <td>
            
              At <a href="https://www.humanbrainmapping.org/i4a/pages/index.cfm?pageid=4229">OHBM 2024</a>, I will present:

<ul>
  <li>
    Educational Course: Communicating neuroscience across peoples, languages, and cultures - <a href="https://drive.google.com/file/d/1iDzJzQPo23HC7gOTYsF7pOAQsMB7KGSO/view?usp=sharing">Interpretable, Reproducible and Creative Neuroimaging Data Visualization</a>
  </li>
  <li>
    Poster Session: Deep independent vector analysis learns linked and identifiable sources from multimodal data
  </li>
  <li>
    BrainArt Exhibition: <a href="https://www.youtube.com/watch?v=yph2hXzY9Dc">Schizosymphony</a>
  </li>
</ul>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec 1, 2023</th>
          <td>
            
              I am honored to receive the Distinguished Scholar Award from the <a href="https://trendscenter.org/">TReNDS Center</a> and the <a href="https://trendscenter.org/d-map/">D-MAP Center</a>. I am grateful to my advisors and collaborators for their trust and support.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 26, 2023</th>
          <td>
            
              I am selected to attend <a href="https://we23.swe.org/">WE23</a>. Thanks Georgia Tech ECE for travel support!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug 24, 2023</th>
          <td>
            
              Two abstracts on multimodal subspace independent vector analysis (MSIVA) and deep independent vector analysis (DeepIVA) are accepted at <a href="http://www.restingstate.com/">RSBC 2023</a>. Thanks RSBC organizers for travel support!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 29, 2023</th>
          <td>
            
              Our paper, <a href="https://www.nature.com/articles/s41562-023-01647-0">Align with the NMIND consortium for better neuroimaging</a>, is published in Nature Human Behaviour!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 19, 2023</th>
          <td>
            
              Two papers are accepted at ICML 2023 workshops:

<ul>
  <li>
    <a href="https://dmlr.ai/assets/accepted-papers/114/CameraReady/ICML_DMLR_2023.pdf">Learning pipeline-invariant representation for robust brain phenotype prediction</a> (<a href="https://dmlr.ai">Data-centric Machine Learning Research Workshop</a>)
  </li>
  <li>
    <a href="https://arxiv.org/abs/2308.14207">Predictive Sparse Manifold Transform</a> (<a href="https://sites.google.com/view/hidimlearning">Workshop on High-dimensional Learning Dynamics</a>)
  </li>
</ul>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 7, 2023</th>
          <td>
            
              I have the pleasure to interview <a href="https://alleninstitute.org/person/hongkui-zeng/">Dr. Hongkui Zeng</a>, the OHBM 2023 Talairach speaker. Check out our <a href="https://www.ohbmbrainmappingblog.com/blog/a-conversation-with-2023-talairach-lecture-presenter-hongkui-zeng">blog post</a> to learn about Hongkuiâ€™s career trajectory, research vision, suggestions to junior researchers, and more!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 13, 2023</th>
          <td>
            
              Three abstracts are accepted at <a href="https://www.humanbrainmapping.org/i4a/pages/index.cfm?pageid=1">OHBM 2023</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 22, 2023</th>
          <td>
            
              Two papers are accepted at <a href="http://2023.biomedicalimaging.org/en/">ISBI 2023</a>:

<ul>
  <li>
    <a href="https://ieeexplore.ieee.org/document/10230492">Evaluating trade-offs in IVA of multimodal neuroimaging using cross-platform multidataset independent subspace analysis</a> (oral)
  </li>
  <li>
    <a href="https://ieeexplore.ieee.org/document/10230605">Multimodal subspace independent vector analysis better captures hidden relationships in multimodal neuroimaging data</a>
  </li>
</ul>

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%78%6C%69%39%39%33@%67%61%74%65%63%68.%65%64%75"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=https://scholar.google.com/citations?user=YKtWorEAAAAJ&hl=en" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>

<a href="https://www.researchgate.net/profile/Xinhui_Li8/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
<a href="https://github.com/XinhuiLi" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/xinhui-li" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>













      </div>
      <div class="contact-note">Please contact me via email.
</div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Xinhui  Li.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: October 29, 2025.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
